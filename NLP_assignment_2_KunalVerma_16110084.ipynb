{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment - 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the necessary libraries and read all the text from the file and then parse it using the sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "with open(\"sherlockholmes.txt\", 'r') as text_file:\n",
    "    text = text_file.read()\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = text.lower()\n",
    "Lines = sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will randomly divide the dataset in 80/20 ratio for training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(Lines)):\n",
    "    test_data.append(Lines[i])\n",
    "\n",
    "train_data =[]\n",
    "\n",
    "for i in range(round(len(Lines)*0.8)):\n",
    "    p=random.choice(test_data)\n",
    "    train_data.append(p)\n",
    "    test_data.remove(p)\n",
    "    \n",
    "#print(len(Lines))\n",
    "#print(len(train_data))\n",
    "#print(len(test_data))\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=[]\n",
    "del_lst=[',','.',\"'s\",'\"','“','”',':','--',\"'\",\"!\",\"''\",'``',';']\n",
    "for i in range(len(train_data)):\n",
    "    wordlist.append('<s>')\n",
    "    wordsperline=word_tokenize(train_data[i])\n",
    "    for j in range(len(wordsperline)):\n",
    "        if wordsperline[j] not in del_lst:\n",
    "            wordlist.append(wordsperline[j])\n",
    "    wordlist.append('</s>')\n",
    "    \n",
    "#print(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Generating all Unigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7476\n"
     ]
    }
   ],
   "source": [
    "Unigram = Counter(wordlist)\n",
    "#print(Unigram)\n",
    "length_unigram=len(Unigram)\n",
    "print(length_unigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for a Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00815944355270198\n"
     ]
    }
   ],
   "source": [
    "def MLE_Unigram(word):\n",
    "    return Unigram[word]/(len(Unigram))\n",
    "\n",
    "print(MLE_Unigram('small'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all Bigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bigram = Counter()\n",
    "\n",
    "for i in range(len(wordlist[:-1])):\n",
    "    if (wordlist[i],wordlist[i+1]) not in Bigram.keys():\n",
    "        Bigram[(wordlist[i],wordlist[i+1])]=1\n",
    "    else:\n",
    "        Bigram[(wordlist[i],wordlist[i+1])]+=1\n",
    "\n",
    "#print(Bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for a Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13262599469496023\n",
      "0.002242152466367713\n"
     ]
    }
   ],
   "source": [
    "def MLE_Bigram(words):\n",
    "    return Bigram[words]/Unigram[words[0]]\n",
    "\n",
    "#Example\n",
    "print(MLE_Bigram(('have', 'been')))\n",
    "print(MLE_Bigram(('is', 'there')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trigram=Counter()\n",
    "for i in range(len(wordlist[:-2])):\n",
    "    if (wordlist[i],wordlist[i+1],wordlist[i+2]) not in Trigram.keys():\n",
    "        Trigram[(wordlist[i],wordlist[i+1],wordlist[i+2])]=1\n",
    "    else:\n",
    "        Trigram[(wordlist[i],wordlist[i+1],wordlist[i+2])]+=1\n",
    "\n",
    "#print(Trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for a trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17338709677419356\n"
     ]
    }
   ],
   "source": [
    "def MLE_Trigram(words):\n",
    "    return Trigram[words]/Bigram[words[:2]]\n",
    "\n",
    "#Example\n",
    "print(MLE_Trigram(('it','is','a')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all quadrgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Quadgram=Counter()\n",
    "for i in range(len(wordlist[:-3])):\n",
    "    if (wordlist[i],wordlist[i+1],wordlist[i+2],wordlist[i+3]) not in Quadgram.keys():\n",
    "        Quadgram[(wordlist[i],wordlist[i+1],wordlist[i+2],wordlist[i+3])]=1\n",
    "    else:\n",
    "        Quadgram[(wordlist[i],wordlist[i+1],wordlist[i+2],wordlist[i+3])]+=1\n",
    "\n",
    "#print(Quadgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE for a quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "def MLE_Quadgram(words):\n",
    "    return Quadgram[words]/Trigram[words[:3]]\n",
    "\n",
    "#Example\n",
    "print(MLE_Quadgram(('should', 'be', 'able', 'to')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Generation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bigram_Sentence_generator():\n",
    "    sentence=\"<s>\"\n",
    "    start_node='<s>'\n",
    "    while(True):\n",
    "        templst=[]\n",
    "        for i in Bigram.keys():\n",
    "            if i[0]==start_node:\n",
    "                templst.append(i)\n",
    "        prob_lst=[MLE_Bigram(i) for i in templst]\n",
    "        k = list(np.random.multinomial(1,prob_lst))\n",
    "        index = k.index(1)\n",
    "        \n",
    "        next_word = templst[index][1]\n",
    "        sentence=sentence+\" \"+next_word\n",
    "        if (next_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start_node = next_word\n",
    "    \n",
    "    return sentence[4:-5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i do not possibly be seen very ill that it down in some years ago\n",
      "it did manual labour that coronet again and there he met you made up a tidy business to the other they have been shattered stern-post of a little management to and i think that case as though the papers\n",
      "thank your own and pa was extremely dark room\n",
      "so i am a large and stormy so at double line of the papers\n",
      "i could hardly be found that i seized with all\n",
      "then at once ?\n",
      "the gentleman ?\n",
      "when he asked sherlock holmes that is writhing limbs and we shall be better put it here and making inquiries as science lost a dozen yards from her hand if you will leave it for i have been drawn and we must have heard of mr\n",
      "one more\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(Bigram_Sentence_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Using Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set the engine at work returning at last however the bumping of the door with the same thickness\n",
      "one ?\n",
      "had she seen someone then ?\n",
      "we shall go down to scotland yard\n",
      "a juryman did you become engaged then ?\n",
      "i shall get the facts are to examine the machine very thoroughly\n",
      "really mr. holmes for i have been trivial in themselves but which have baffled all those great elemental forces which shriek at mankind through the care of his note-book and handed it up in a few paces of the hall behind her landau when a sudden indisposition and retired to her\n",
      "nothing was to be read upon the lining\n",
      "she showed me as being a traveller in wines\n",
      "'yes our little friend will not suffer from her carriage rattle off down the room and by evening i would find that he had laid down his arms\n",
      "it was his habit when in high spirits\n",
      "'i was admiring your fuller's-earth said i 'i opened the door of briony lodge\n",
      "of course inferred that his nervous system is shattered\n",
      "the station-master laughed heartily\n",
      "and i drew the drawer ?\n",
      "i passed you without a word he grasped my arm and hurried down to arduous work at 2 pounds\n",
      "what a week\n",
      "'keep your forgiveness for those peculiar qualities which my friend sherlock holmes was well known to the house\n",
      "those are the geese ?\n",
      "there was a lad of eighteen and turner had an eastern training\n"
     ]
    }
   ],
   "source": [
    "def Trigram_Sentence_generator():\n",
    "    sentence=\"<s>\"\n",
    "    templst=[]\n",
    "    for i in Bigram.keys():\n",
    "        if i[0]=='<s>':\n",
    "            templst.append(i)\n",
    "    prob_lst=[MLE_Bigram(i) for i in templst]\n",
    "    k = list(np.random.multinomial(1,prob_lst))\n",
    "    index = k.index(1)\n",
    "        \n",
    "    next_word = templst[index][1]\n",
    "    sentence=sentence+\" \"+next_word\n",
    "        \n",
    "    start_node=('<s>',next_word)\n",
    "    while(True):\n",
    "        templst=[]\n",
    "        for i in Trigram.keys():\n",
    "            if i[0:2]==start_node:\n",
    "                templst.append(i)\n",
    "        prob_lst=[MLE_Trigram(i) for i in templst]\n",
    "        k = list(np.random.multinomial(1,prob_lst))\n",
    "        index = k.index(1)\n",
    "        \n",
    "        next_word = templst[index][-1]\n",
    "        sentence=sentence+\" \"+next_word\n",
    "        if (next_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start_node = (start_node[1],next_word)\n",
    "    \n",
    "    return sentence[4:-5]\n",
    "\n",
    "for i in range(20):\n",
    "    print(Trigram_Sentence_generator())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using quadgram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my heart had turned to lead\n",
      "a clump of laurel bushes there darted what seemed to me to be the worse for the fall\n",
      "the most lay silent but some muttered to themselves and others talked together in a strange low monotonous voice their conversation coming in gushes and then suddenly just at the stroke of eleven a single bright light shone out right in front of briony lodge was open and the prisoner gone\n",
      "it was a cold night the sweat was pouring down my face before i came to myself\n",
      "the newcomers were colonel lysander stark\n",
      "i gave the maid a card but i see that she was sick with fear and astonishment upon her broad good-humoured face\n",
      "it seemed to me that whatever happened i was to my interest to buy their land before they discovered its true value but unfortunately i had no idea that he was too good and kind to leave me but she paused at the door\n",
      "as low as you can he answered i have excellent ears\n",
      "then there is no sign of any violence upon her\n",
      "all right said jones with a stare and a snigger\n"
     ]
    }
   ],
   "source": [
    "def Quadgram_Sentence_generator():\n",
    "    \n",
    "    sentence=\"<s>\"\n",
    "    templst=[]\n",
    "    for i in Bigram.keys():\n",
    "        if i[0]=='<s>':\n",
    "            templst.append(i)\n",
    "    prob_lst=[MLE_Bigram(i) for i in templst]\n",
    "    k = list(np.random.multinomial(1,prob_lst))\n",
    "    index = k.index(1)\n",
    "        \n",
    "    next_word1 = templst[index][1]\n",
    "    sentence=sentence+\" \"+next_word1\n",
    "\n",
    "    \n",
    "    templst=[]\n",
    "    for i in Trigram.keys():\n",
    "            if i[0:2]==('<s>',next_word1):\n",
    "                templst.append(i)\n",
    "    prob_lst=[MLE_Trigram(i) for i in templst]\n",
    "    k = list(np.random.multinomial(1,prob_lst))\n",
    "    index = k.index(1)\n",
    "        \n",
    "    next_word2 = templst[index][-1]\n",
    "    sentence=sentence+\" \"+next_word2\n",
    "    \n",
    "    \n",
    "    start_node=('<s>',next_word1,next_word2)\n",
    "\n",
    "    while(True):\n",
    "        templst=[]\n",
    "        for i in Quadgram.keys():\n",
    "            if i[0:3]==start_node:\n",
    "                templst.append(i)\n",
    "        prob_lst=[MLE_Quadgram(i) for i in templst]\n",
    "        k = list(np.random.multinomial(1,prob_lst))\n",
    "        index = k.index(1)\n",
    "        \n",
    "        next_word = templst[index][-1]\n",
    "        sentence=sentence+\" \"+next_word\n",
    "        if (next_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start_node = (start_node[1],start_node[2],next_word)\n",
    "    \n",
    "    return sentence[4:-5]\n",
    "\n",
    "for i in range(10):\n",
    "    print(Quadgram_Sentence_generator())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining function for sentence generation according to order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is model_name k=1 bigram k=2 trigram k=3 quadgram\n",
    "def generator(k):\n",
    "    if k==1:\n",
    "        return Bigram_Sentence_generator()\n",
    "    elif k==2:\n",
    "        return Trigram_Sentence_generator()\n",
    "    elif k==3:\n",
    "        return Quadgram_Sentence_generator()\n",
    "    else:\n",
    "        return \"Model No. does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LogProbabilitySentence(sentence,k):\n",
    "    \n",
    "    if k==0:\n",
    "        probability=0\n",
    "        for i in range(len(sentence)):\n",
    "            probability+=math.log(MLE_Unigram(sentence[i]))\n",
    "        return probability\n",
    "    \n",
    "    elif k==1:\n",
    "        probability=math.log(MLE_Unigram(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            probability+=math.log(MLE_Bigram(sentence[i:i+2]))\n",
    "        return probability\n",
    "    \n",
    "    elif k==2:\n",
    "        probability=math.log(MLE_Unigram(sentence[0]))+math.log(MLE_Bigram(sentence[0:2]))\n",
    "        for i in range(len(sentence)-2):\n",
    "            probability+=math.log(MLE_Trigram(sentence[i:i+3]))\n",
    "        return probability\n",
    "    \n",
    "    elif k==3:\n",
    "        probability=math.log(MLE_Unigram(sentence[0]))+math.log(MLE_Bigram(sentence[0:2]))+math.log(MLE_Trigram(sentence[0:3]))\n",
    "        for i in range(len(sentence)-3):\n",
    "            probability+=math.log(MLE_Quadgram(sentence[i:i+4]))\n",
    "        return probability\n",
    "    elif k==4:\n",
    "        probability=math.log(MLE_Unigram(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            probability+=math.log(Add_One_prob(sentence[i:i+2]))\n",
    "        return probability\n",
    "\n",
    "    elif k==5:\n",
    "        probability=math.log(MLE_Unigram(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            value = math.log(Good_turing_prob(sentence[i:i+2]))\n",
    "            probability+=value\n",
    "        return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 1 Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function caclulating effective count post add one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.90929577464789\n"
     ]
    }
   ],
   "source": [
    "def Bigram_addone(i,j):\n",
    "    if (i,j) in Bigram.keys():\n",
    "        count = (Bigram[(i,j)]+1)*(Unigram[i])/(Unigram[i]+len(Unigram))\n",
    "    else:\n",
    "        count =(Unigram[i])/(Unigram[i]+len(Unigram))\n",
    "    return count\n",
    "\n",
    "print(Bigram_addone('in', 'the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for Add one smoothing probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Add_One_prob(words):\n",
    "    if words in Bigram.keys():\n",
    "        probability = (Bigram[words]+1)/(Unigram[words[0]]+len(Unigram))\n",
    "    else:\n",
    "        probability = 1/(Unigram[words[0]]+len(Unigram))\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.30767303476354524  :  0.6923269652364548\n",
      "2 1.1195032573289903  :  0.8804967426710097\n",
      "3 2.0120021822149483  :  0.9879978177850517\n",
      "4 2.9121475054229933  :  1.0878524945770067\n",
      "5 3.787709497206704  :  1.2122905027932962\n",
      "6 5.678466076696165  :  0.3215339233038348\n",
      "7 5.701818181818182  :  1.2981818181818179\n",
      "8 6.933673469387755  :  1.066326530612245\n",
      "9 7.483443708609271  :  1.516556291390729\n",
      "10 9.63716814159292  :  0.36283185840708043\n"
     ]
    }
   ],
   "source": [
    "Bigram_list=list(Bigram.values())\n",
    "freqoffreq={}  \n",
    "for i in range(len(Bigram_list)):\n",
    "    if Bigram_list[i] not in freqoffreq:\n",
    "        freqoffreq[Bigram_list[i]]=1\n",
    "    else:\n",
    "        freqoffreq[Bigram_list[i]]+=1\n",
    "\n",
    "Turing_count={}\n",
    "for i in range(1,11):\n",
    "    Turing_count[i] = freqoffreq[i+1]*(i+1)/freqoffreq[i]\n",
    "    print (i ,Turing_count[i],\" : \", i-Turing_count[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function for good turing probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Good_turing_prob(words):\n",
    "    discounting_value=0.95\n",
    "    if words in Bigram.keys():\n",
    "        i=Bigram[words]\n",
    "        probability = (i-discounting_value)/Unigram[words[0]]\n",
    "    else:\n",
    "        probability=freqoffreq[1]/len(Bigram.values())\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average discounting value :  0.9426394944958526\n"
     ]
    }
   ],
   "source": [
    "d=0\n",
    "for i in range(1,11):\n",
    "    d+= i-Turing_count[i]\n",
    "    \n",
    "print (\"discounting value : \",d/10.0 )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets=[]\n",
    "del_lst=[',','.',\"'s\",'\"','“','”',':','--',\"'\",\"!\",\"''\",'``',';']\n",
    "for i in range(len(test_data)):\n",
    "    sets.append('<s>')\n",
    "    tests_line=word_tokenize(test_data[i])\n",
    "    for j in range(len(tests_line)):\n",
    "        if tests_line[j] not in del_lst:\n",
    "            sets.append(tests_line[j])\n",
    "    sets.append('</s>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "testing_list=[]\n",
    "testing_sentence=[]\n",
    "for i in range(len(tests)):\n",
    "    testing_sentence.append(tests[i])\n",
    "    if (tests[i]=='</s>'):\n",
    "        testing_list.append(tuple(testing_sentence))\n",
    "        testing_sentence=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity ( add one ):  1057.1068126768903\n"
     ]
    }
   ],
   "source": [
    "Probability_log = LogProbabilitySentence(tuple(tests),4)\n",
    "perplexity = math.exp(-1*Probability_log/len(tests))\n",
    "\n",
    "print (\"Perplexity ( add one ): \",perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (good turing):  14.307546332304208\n"
     ]
    }
   ],
   "source": [
    "Probability_log = LogProbabilitySentence(tuple(tests),5)\n",
    "perplexity = math.exp(-1*Probability_log/len(tests))\n",
    "\n",
    "print (\"Perplexity (good turing): \",perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
